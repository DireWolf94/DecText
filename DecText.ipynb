{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = torch.load(\"pruned.pkl\")\n",
    "#loading libraries\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLinear(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(MaskedLinear, self).__init__(in_features, out_features, bias)\n",
    "        self.mask_flag = False\n",
    "    \n",
    "    def set_mask(self, mask):\n",
    "        self.register_buffer('mask', mask)\n",
    "        mask_var = self.get_mask()\n",
    "        self.weight.data = self.weight.data*mask_var.data\n",
    "        self.mask_flag = True\n",
    "    \n",
    "    def get_mask(self):\n",
    "        # print(self.mask_flag)\n",
    "        return Variable(self.mask, requires_grad=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.mask_flag == True:\n",
    "            mask_var = self.get_mask()\n",
    "            weight = self.weight * mask_var\n",
    "            return F.linear(x, weight, self.bias)\n",
    "        else:\n",
    "            return F.linear(x, self.weight, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network definition\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = MaskedLinear(input_size, hidden_size,bias=1) \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.fc2 = MaskedLinear(hidden_size, num_classes,bias=1)\n",
    "        self.sigm=nn.Sigmoid()\n",
    "    \n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.fc1(x)\n",
    "        x=self.tanh(x)\n",
    "        out=self.fc2(x)\n",
    "        out=self.sigm(out)\n",
    "        \n",
    "        return out\n",
    "    def store_neuron_outputs(self,x):\n",
    "        x=self.fc1(x)\n",
    "        x=self.tanh(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def set_masks(self, masks):\n",
    "        self.fc1.set_mask(masks[0])\n",
    "        self.fc2.set_mask(masks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatrain=pd.read_csv('Iris.csv')\n",
    "datatrain.loc[datatrain['Species']=='Iris-setosa', 'Species']=0\n",
    "datatrain.loc[datatrain['Species']=='Iris-versicolor', 'Species']=1\n",
    "datatrain.loc[datatrain['Species']=='Iris-virginica', 'Species']=2\n",
    "datatrain = datatrain.apply(pd.to_numeric)\n",
    "datatrain=np.array(datatrain)\n",
    "datatrain=datatrain[:,1:6]\n",
    "\n",
    "\n",
    "#split x and y (feature and target)\n",
    "X = datatrain[:,0:4]\n",
    "y = datatrain[:,4]\n",
    "\n",
    "#y=pd.get_dummies(y)\n",
    "#y=np.array(y)\n",
    "net = torch.load(\"pruned.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): MaskedLinear(in_features=4, out_features=1, bias=True)\n",
       "  (tanh): Tanh()\n",
       "  (fc2): MaskedLinear(in_features=1, out_features=3, bias=True)\n",
       "  (sigm): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data= Variable(torch.Tensor(X)).float()\n",
    "out=net(X_data).data.numpy()\n",
    "_, predicted = torch.max(net(X_data).data, 1)\n",
    "for index,row in enumerate(datatrain):\n",
    "    row[-1]=predicted.numpy()[index]\n",
    "dataset=(datatrain,out)\n",
    "datatrain=datatrain[:,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predicted.numpy(),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSE_value(teaching_outputs,NN_outputs):\n",
    "    # teaching_outputs and NN_outputs is of size mxn where m=no. of examples and n is no. of classes in output vector.\n",
    "    sse=np.sum(np.square(teaching_outputs-NN_outputs))\n",
    "    return sse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_classes=3\n",
    "def get_majority_class(data):\n",
    "    X_data_actual=Variable(torch.Tensor(data)).float()\n",
    "    actual_out=net(X_data_actual).data.numpy()\n",
    "    _, actual_predicted = torch.max(net(X_data_actual).data, 1)\n",
    "    outcomes=list(actual_predicted.numpy())\n",
    "    return max(set(outcomes), key=outcomes.count)\n",
    "\n",
    "def get_NNoutputs(data):\n",
    "    X_data_actual=Variable(torch.Tensor(data)).float()\n",
    "    actual_out=net(X_data_actual).data.numpy()\n",
    "    _, actual_predicted = torch.max(net(X_data_actual).data, 1)\n",
    "    return actual_out\n",
    "\n",
    "# Calculate the SSE index for a split dataset\n",
    "def SSE_index(groups):\n",
    "    # count all samples at split point\n",
    "    no_of_instances=len(groups[0])+len(groups[1])\n",
    "    \n",
    "    sse_value_sum = 0.0\n",
    "    \n",
    "    for group in groups:\n",
    "        size=len(group)\n",
    "        sse_value=0.0\n",
    "        \n",
    "        # avoid divide by zero\n",
    "        if size == 0:\n",
    "            continue\n",
    "            \n",
    "        maj_class=get_majority_class(group)\n",
    "        \n",
    "        one_hot_teaching=np.zeros((group.shape[0],no_of_classes))\n",
    "        for i in range(len(one_hot_teaching)):\n",
    "            one_hot_teaching[i][maj_class]=1\n",
    "        N_N_outputs=get_NNoutputs(group)\n",
    "        \n",
    "        sse_value=size*SSE_value(one_hot_teaching,N_N_outputs)/no_of_instances\n",
    "        \n",
    "        sse_value_sum=sse_value_sum+sse_value\n",
    "        \n",
    "    return sse_value_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a dataset based on an attribute and an attribute value\n",
    "def test_split(index, value, data):\n",
    "    left, right = list(), list()\n",
    "    for row in data:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return np.array(left), np.array(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def best_feature(data):\n",
    "    sub_data=data.copy()\n",
    "    feature_index=0\n",
    "    max_cost=0\n",
    "    for i in range(0,np.size(sub_data,1)):\n",
    "        zero_feature_data=sub_data.copy()\n",
    "        zero_feature_data[:,i]=0\n",
    "        \n",
    "        X_data_zero= Variable(torch.Tensor(zero_feature_data)).float()\n",
    "        zero_out=net(X_data).data.numpy()\n",
    "        _, zero_predicted = torch.max(net(X_data_zero).data, 1)\n",
    "        \n",
    "        X_data_actual=Variable(torch.Tensor(sub_data)).float()\n",
    "        actual_out=net(X_data_actual).data.numpy()\n",
    "        _, actual_predicted = torch.max(net(X_data_actual).data, 1)\n",
    "        \n",
    "        one_hot_teaching=np.zeros_like(zero_out)\n",
    "        for j in range(len(zero_predicted)):\n",
    "            one_hot_teaching[j][zero_predicted[j]]=1\n",
    "            \n",
    "        cost=SSE_value(one_hot_teaching,zero_out)\n",
    "        print(cost)\n",
    "        if max_cost<cost:\n",
    "            max_cost=cost\n",
    "            feature_index=i\n",
    "    #print(feature_index)   \n",
    "    return feature_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select the best split point for a dataset for a feature\n",
    "def get_split(data,feature):\n",
    "    b_value, b_score, b_groups = 999, 999, None\n",
    "    for row in data:\n",
    "        groups = test_split(feature, row[feature], data)\n",
    "        sse = SSE_index(groups)\n",
    "        if sse < b_score:\n",
    "            b_value, b_score, b_groups = row[feature], sse, groups\n",
    "    return {'index':feature, 'value':b_value, 'groups':b_groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_terminal(group):\n",
    "    X_data_actual=Variable(torch.Tensor(group)).float()\n",
    "    actual_out=net(X_data_actual).data.numpy()\n",
    "    _, actual_predicted = torch.max(net(X_data_actual).data, 1)\n",
    "    outcomes=list(actual_predicted.numpy())\n",
    "    return max(set(outcomes), key=outcomes.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    # check for a no split\n",
    "    if not left.tolist() or not right.tolist():\n",
    "        print(left.shape)\n",
    "        print(right.shape)\n",
    "        if(left.shape[0]==0 and right.shape[0]!=0):\n",
    "            node['left'] = node['right'] = to_terminal(right)\n",
    "        elif(right.shape[0]==0 and left.shape[0]!=0):\n",
    "            node['left'] = node['right'] = to_terminal(left)\n",
    "        else:\n",
    "            node['left'] = node['right'] = to_terminal(np.concatenate((left,right),axis=0))\n",
    "        return\n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    # process left child\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        b_feature=best_feature(left)\n",
    "        node['left'] = get_split(left,b_feature)\n",
    "        split(node['left'], max_depth, min_size, depth+1)\n",
    "    # process right child\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        b_feature=best_feature(right)\n",
    "        node['right'] = get_split(right,b_feature)\n",
    "        split(node['right'], max_depth, min_size, depth+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size):\n",
    "    feature=best_feature(train)\n",
    "    root = get_split(train,feature)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    \n",
    "    print(correct / float(len(actual)) * 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.25941\n",
      "34.25941\n",
      "166.46089\n",
      "100.03233\n",
      "73.24859\n",
      "73.24859\n",
      "91.53776\n",
      "81.30214\n",
      "66.552155\n",
      "66.552155\n",
      "66.552155\n",
      "66.552155\n",
      "88.507774\n",
      "88.507774\n",
      "88.507774\n",
      "88.507774\n",
      "100.47806\n",
      "100.47806\n",
      "100.47806\n",
      "100.47806\n",
      "107.46632\n",
      "107.46632\n",
      "107.46632\n",
      "107.46632\n",
      "109.4629\n",
      "109.4629\n",
      "109.4629\n",
      "109.4629\n",
      "104.47179\n",
      "104.47179\n",
      "104.47179\n",
      "104.47179\n",
      "108.464714\n",
      "108.464714\n",
      "108.464714\n",
      "108.464714\n",
      "(0,)\n",
      "(8, 4)\n",
      "94.49185\n",
      "94.49185\n",
      "94.49185\n",
      "94.49185\n",
      "105.469696\n",
      "105.469696\n",
      "105.469696\n",
      "105.469696\n",
      "108.464714\n",
      "108.464714\n",
      "108.464714\n",
      "108.464714\n",
      "(0,)\n",
      "(8, 4)\n",
      "105.469696\n",
      "105.469696\n",
      "105.469696\n",
      "105.469696\n",
      "110.461044\n",
      "110.461044\n",
      "110.461044\n",
      "110.461044\n",
      "123.14581\n",
      "123.14581\n",
      "91.500854\n",
      "109.22098\n",
      "119.931526\n",
      "119.931526\n",
      "103.473175\n",
      "108.53776\n",
      "118.59224\n",
      "118.59224\n",
      "108.464714\n",
      "113.52725\n",
      "119.66367\n",
      "119.66367\n",
      "104.47179\n",
      "117.13343\n",
      "118.32439\n",
      "118.32439\n",
      "109.4629\n",
      "115.791695\n",
      "172.12335\n",
      "172.12335\n",
      "91.53776\n",
      "137.27081\n",
      "139.46724\n",
      "139.46724\n",
      "82.519264\n",
      "125.55653\n",
      "127.592255\n",
      "127.592255\n",
      "99.479965\n",
      "121.00296\n",
      "119.788666\n",
      "119.788666\n",
      "109.4629\n",
      "118.32439\n",
      "124.25296\n",
      "124.25296\n",
      "106.46788\n",
      "119.12796\n",
      "128.32439\n",
      "128.32439\n",
      "99.479965\n",
      "121.00296\n",
      "121.52081\n",
      "121.52081\n",
      "108.464714\n",
      "118.59224\n",
      "123.25296\n",
      "123.25296\n",
      "107.46632\n",
      "118.8601\n",
      "(0,)\n",
      "(9, 4)\n",
      "150.8601\n",
      "150.8601\n",
      "75.52998\n",
      "128.16368\n",
      "133.05653\n",
      "133.05653\n",
      "95.4893\n",
      "122.07439\n",
      "125.98511\n",
      "125.98511\n",
      "105.469696\n",
      "119.39581\n",
      "121.71724\n",
      "121.71724\n",
      "110.461044\n",
      "118.056526\n",
      "(0,)\n",
      "(6, 4)\n",
      "123.52081\n",
      "123.52081\n",
      "106.46788\n",
      "119.12796\n",
      "122.98511\n",
      "122.98511\n",
      "108.464714\n",
      "118.59224\n",
      "(0,)\n",
      "(8, 4)\n",
      "134.25296\n",
      "134.25296\n",
      "96.48688\n",
      "122.53868\n",
      "122.25296\n",
      "122.25296\n",
      "108.464714\n",
      "118.59224\n",
      "128.44939\n",
      "128.44939\n",
      "104.47179\n",
      "120.39581\n",
      "122.44939\n",
      "122.44939\n",
      "110.461044\n",
      "118.056526\n",
      "122.44939\n",
      "122.44939\n",
      "110.461044\n",
      "118.78867\n"
     ]
    }
   ],
   "source": [
    "tree = build_tree(datatrain, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 2,\n",
       " 'value': 4.4,\n",
       " 'left': {'index': 2,\n",
       "  'value': 3.0,\n",
       "  'left': {'index': 0,\n",
       "   'value': 5.1,\n",
       "   'left': {'index': 0,\n",
       "    'value': 4.9,\n",
       "    'left': {'index': 0,\n",
       "     'value': 4.7,\n",
       "     'left': {'index': 0, 'value': 4.6, 'left': 0, 'right': 0},\n",
       "     'right': {'index': 0, 'value': 4.8, 'left': 0, 'right': 0}},\n",
       "    'right': {'index': 0,\n",
       "     'value': 5.0,\n",
       "     'left': 0,\n",
       "     'right': {'index': 0, 'value': 5.0, 'left': 0, 'right': 0}}},\n",
       "   'right': {'index': 0,\n",
       "    'value': 5.3,\n",
       "    'left': {'index': 0,\n",
       "     'value': 5.2,\n",
       "     'left': {'index': 0, 'value': 5.1, 'left': 0, 'right': 0},\n",
       "     'right': 0},\n",
       "    'right': {'index': 0,\n",
       "     'value': 5.5,\n",
       "     'left': {'index': 0, 'value': 5.4, 'left': 0, 'right': 0},\n",
       "     'right': 0}}},\n",
       "  'right': {'index': 0,\n",
       "   'value': 5.7,\n",
       "   'left': {'index': 0,\n",
       "    'value': 5.5,\n",
       "    'left': 1,\n",
       "    'right': {'index': 0, 'value': 5.6, 'left': 1, 'right': 1}},\n",
       "   'right': {'index': 0,\n",
       "    'value': 5.9,\n",
       "    'left': {'index': 0, 'value': 5.8, 'left': 1, 'right': 1},\n",
       "    'right': 1}}},\n",
       " 'right': {'index': 0,\n",
       "  'value': 6.4,\n",
       "  'left': {'index': 0,\n",
       "   'value': 6.1,\n",
       "   'left': {'index': 0,\n",
       "    'value': 5.8,\n",
       "    'left': {'index': 0, 'value': 5.6, 'left': 1, 'right': 1},\n",
       "    'right': {'index': 0, 'value': 6.0, 'left': 2, 'right': 1}},\n",
       "   'right': {'index': 0,\n",
       "    'value': 6.3,\n",
       "    'left': {'index': 0, 'value': 6.2, 'left': 1, 'right': 2},\n",
       "    'right': {'index': 0, 'value': 6.3, 'left': 2, 'right': 2}}},\n",
       "  'right': {'index': 0,\n",
       "   'value': 6.8,\n",
       "   'left': {'index': 0,\n",
       "    'value': 6.6,\n",
       "    'left': {'index': 0,\n",
       "     'value': 6.5,\n",
       "     'left': {'index': 0, 'value': 6.4, 'left': 2, 'right': 2},\n",
       "     'right': 2},\n",
       "    'right': {'index': 0,\n",
       "     'value': 6.7,\n",
       "     'left': 1,\n",
       "     'right': {'index': 0, 'value': 6.7, 'left': 2, 'right': 2}}},\n",
       "   'right': {'index': 0,\n",
       "    'value': 7.1,\n",
       "    'left': {'index': 0, 'value': 6.9, 'left': 2, 'right': 2},\n",
       "    'right': {'index': 0,\n",
       "     'value': 7.6,\n",
       "     'left': {'index': 0, 'value': 7.3, 'left': 2, 'right': 2},\n",
       "     'right': {'index': 0, 'value': 7.9, 'left': 2, 'right': 2}}}}}}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=0\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=1\n",
      "Got=2\n",
      "Got=1\n",
      "Got=2\n",
      "Got=1\n",
      "Got=1\n",
      "Got=1\n",
      "Got=1\n",
      "Got=1\n",
      "Got=1\n",
      "Got=1\n",
      "Got=1\n",
      "Got=2\n",
      "Got=1\n",
      "Got=1\n",
      "Got=2\n",
      "Got=1\n",
      "Got=2\n",
      "Got=1\n",
      "Got=2\n",
      "Got=1\n",
      "Got=1\n",
      "Got=1\n",
      "Got=2\n",
      "Got=2\n",
      "Got=1\n",
      "Got=1\n",
      "Got=1\n",
      "Got=1\n",
      "Got=1\n",
      "Got=1\n",
      "Got=1\n",
      "Got=1\n",
      "Got=2\n",
      "Got=2\n",
      "Got=1\n",
      "Got=1\n",
      "Got=1\n",
      "Got=1\n",
      "Got=1\n",
      "Got=1\n",
      "Got=1\n",
      "Got=1\n",
      "Got=1\n",
      "Got=1\n",
      "Got=1\n",
      "Got=1\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=1\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=1\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=1\n",
      "Got=2\n",
      "Got=1\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=1\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=1\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=1\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n",
      "Got=2\n"
     ]
    }
   ],
   "source": [
    "predicted_1=[]\n",
    "for row in datatrain:\n",
    "    prediction = predict(tree, row)\n",
    "    predicted_1.append(prediction)\n",
    "    print('Got=%d' % (prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.66666666666667"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_metric(predicted.numpy(),predicted_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
